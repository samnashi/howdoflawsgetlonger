{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-6-18c4cbd1e3ac>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-18c4cbd1e3ac>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    for index in range(data.shape[1]):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "'''Example script showing how to use stateful RNNs\n",
    "to model long sequences efficiently.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Flatten, Input, Reshape, TimeDistributed\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "def np_array_pair_generator(data,labels): #shape is something like 1, 11520, 11\n",
    "    while 1:\n",
    "    for index in range(data.shape[1]):\n",
    "        # create Numpy arrays of input data\n",
    "        # and labels, from each line in the file\n",
    "        x = data[1,index,:]\n",
    "        y = labels[1,index,:]\n",
    "        yield (x, y)\n",
    "\n",
    "# since we are using stateful rnn tsteps can be set to 1\n",
    "tsteps = 1\n",
    "batch_size = 2\n",
    "epochs = 25\n",
    "\n",
    "# number of elements ahead that are used to make the prediction\n",
    "lahead = 1\n",
    "\n",
    "#raw_path = \"/home/ihsan/Documents/thesis_generator/results/devin/to_process/\" #needs the absolute path, no tildes!\n",
    "#processed_path = \"/home/ihsan/Documents/thesis_generator/results/devin\"\n",
    "train_path = \"/home/ihsan/Documents/thesis_models/train/\"\n",
    "test_path = \"/home/ihsan/Documents/thesis_models/test/\"\n",
    "\n",
    "#11 input columns\n",
    "#4 output columns.\n",
    "\n",
    "\n",
    "\n",
    "#load data multiple times.\n",
    "data_filenames = os.listdir(train_path + \"data\")\n",
    "#print(\"before sorting, data_filenames: {}\".format(data_filenames))\n",
    "data_filenames.sort()\n",
    "#print(\"after sorting, data_filenames: {}\".format(data_filenames))\n",
    "\n",
    "\n",
    "label_filenames = os.listdir(train_path + \"label\")\n",
    "label_filenames.sort()\n",
    "#print(\"label_filenames: {}\".format(data_filenames))\n",
    "combined_filenames = zip(data_filenames,label_filenames)\n",
    "print(combined_filenames)\n",
    "assert len(data_filenames) == len(label_filenames)\n",
    "\n",
    "'''print('Creating Model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,\n",
    "               input_shape = (None,11),\n",
    "               return_sequences=True,\n",
    "               stateful=False))\n",
    "model.add(LSTM(64,return_sequences=False,stateful=False))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mse', optimizer='rmsprop')'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1 / 25\n",
      "Epoch 2 / 25\n",
      "Epoch 3 / 25\n",
      "Epoch 4 / 25\n",
      "Epoch 5 / 25\n",
      "Epoch 6 / 25\n",
      "Epoch 7 / 25\n",
      "Epoch 8 / 25\n",
      "Epoch 9 / 25\n",
      "Epoch 10 / 25\n",
      "Epoch 11 / 25\n",
      "Epoch 12 / 25\n",
      "Epoch 13 / 25\n",
      "Epoch 14 / 25\n",
      "Epoch 15 / 25\n",
      "Epoch 16 / 25\n",
      "Epoch 17 / 25\n",
      "Epoch 18 / 25\n",
      "Epoch 19 / 25\n",
      "Epoch 20 / 25\n",
      "Epoch 21 / 25\n",
      "Epoch 22 / 25\n",
      "Epoch 23 / 25\n",
      "Epoch 24 / 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"print('Plotting Results')\\nplt.subplot(2, 1, 1)\\nplt.plot(label_array)\\nplt.title('Expected')\\nplt.subplot(2, 1, 2)\\nplt.plot(predicted_output)\\nplt.title('Predicted')\\nplt.show()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.summary()\n",
    "#define the model first\n",
    "#a = Input(batch_shape=(batch_size,None,11))\n",
    "a = Input(shape=(None,11))\n",
    "b = LSTM(64,return_sequences=True)(a)\n",
    "c = LSTM(64,return_sequences=False)(b)\n",
    "#c = Dense(128)(c)\n",
    "#c = Flatten()(c)\n",
    "#c = Reshape(target_shape=(11520,5))(c)\n",
    "#out = TimeDistributed(Dense(4))(c)\n",
    "out = Dense(4)(c)\n",
    "\n",
    "model = Model(inputs=a,outputs=out)\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "print(\"Inputs: {}\".format(model.input_shape))\n",
    "print (\"Outputs: {}\".format(model.output_shape))\n",
    "#print (\"Actual input: {}\".format(data.shape))\n",
    "#print (\"Actual output: {}\".format(target.shape))\n",
    "'''\n",
    "print('loading data...')\n",
    "\n",
    "#tuples\n",
    "for files in combined_filenames:\n",
    "    data_load_path = train_path + '/data/' + files[0]\n",
    "    label_load_path = train_path + '/label/' + files[1]\n",
    "    #print(\"data/label load path: {} \\n {}\".format(data_load_path,label_load_path))\n",
    "    train_array = np.load(data_load_path)\n",
    "    label_array = np.load(label_load_path)\n",
    "    train_array = np.reshape(train_array,(1,train_array.shape[0],train_array.shape[1]))\n",
    "    label_array = np.reshape(label_array,(1,label_array.shape[0],label_array.shape[1]))\n",
    "    #print(\"data/label shape: {} \\n {}\".format(train_array.shape,label_array.shape))\n",
    "    \n",
    "    generator = np_array_pair_generator(train_array,label_array)\n",
    "\n",
    "    print('Training')\n",
    "    for i in range(epochs):\n",
    "        print('Epoch', i, '/', epochs)\n",
    "        generator.next\n",
    "        #model.fit_generator(np_array_pair_generator(train_array,label_array),epochs=10,steps_per_epoch=1)\n",
    "\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in cos.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with cos[i::batch_size].\n",
    "\n",
    "        #model.fit(train_array, label_array)\n",
    "#print('Predicting')\n",
    "#predicted_output = model.predict(cos, batch_size=batch_size)\n",
    "'''print('Plotting Results')\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(label_array)\n",
    "plt.title('Expected')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(predicted_output)\n",
    "plt.title('Predicted')\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
